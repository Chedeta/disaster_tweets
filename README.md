# Projet Disaster Tweets : reconnaissance de tweets sur des catastrophes

üé¨ <a href='https://share.vidyard.com/watch/iKq2CRoskhWXJb9YPP2ioX?'>Cliquer ici pour la vid√©o de pr√©sentation du projet</a>

## 1. Objectif

Twitter est devenu un important r√©seau de communication en cas d'urgence. L'omnipr√©sence des smartphones permet aux gens d'annoncer une urgence qu'ils observent en temps r√©el. C'est pourquoi de plus en plus d'organismes s'int√©ressent √† la surveillance programmatique de Twitter (par exemple, les organisations de secours en cas de catastrophe et les agences de presse).

Ainsi, le projet "Disaster Tweets" a pour but, √† l'aide d'outils de deep learning, de reconna√Ætre des tweets rev√™tant d'une vraie catastrophe, prenant ainsi en compte le contexte, exemple :
<ol>
  <li>"I would kill to eat"</li>
  <li>"I would kill him"</li>
</ol>
La (1) et la (2) poss√®dent le m√™me mot clef "kill", le premier ne rev√™t cependant pas d'un caract√®re dangereux contrairement au deuxi√®me.

## 2. Data overview

Le training set poss√®de 7503 tweets r√©partis de la fa√ßon suivante :

![download](https://user-images.githubusercontent.com/96300465/199680269-ae864f0b-9325-4536-b222-9253620c14cd.png)

Le dataset de training est assez √©quilibr√©, cependant les donn√©es √©tant extraites du site Twitter, un pre-processing sur les caract√®res est n√©cessaire afin de pouvoir entra√Æner les algorithmes, avec <code>regex</code> pour le nettoyage des caract√®res sp√©ciaux et <code>spacy</code> pour la lemmatisation.

## 3. Aper√ßu des r√©sultats 

Pour t√©moigner de la qualit√© du pre-processing, un <code>wordcloud</code> a √©t√© effectu√© sur chacune des target du dataset de train :

Target = 0 (non-disaster tweet) :
![download](https://user-images.githubusercontent.com/96300465/199686110-3fa28cc7-1222-4e62-9bec-a01eb5af26a3.png)

Target = 1 (disaster tweet) :
![download](https://user-images.githubusercontent.com/96300465/199686127-c549e3d5-c79f-4637-8dcd-17b48b2fd6f2.png)

On retrouve des mots clef du champ lexical de la catastrophe dans le deuxi√®me <code>wordcloud</code> que l'on ne retrouve pas dans le premier.

Ainsi, pour l'entrainement du mod√®le, le module <code>keras</code> de <code>TensorFlow</code> a √©t√© utilis√©. Le mod√®le optimal comporte ainsi 4 couches dont deux fonctions d'activation, une relu et une sigmoid pour les r√©sultats suivants :

![download](https://user-images.githubusercontent.com/96300465/199682061-9c33726a-cf4d-4b2e-b311-40020dc8cffa.png)

## 4. Cr√©dits

Auteurs : Jean Ivars, avec la participation d'<a href='https://github.com/Bebock'>H√©l√®ne</a>
